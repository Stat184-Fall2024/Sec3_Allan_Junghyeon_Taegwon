---
title: "[Stat 184] Final Project"
subtitle: Netflix Content Analyis 
author:
  - name: Allan Samoilovich
    corresponding: true
  - name: Junghyeon Sung
    corresponding: true
  - name: Taegwon Lee
    corresponding: true
date: 12/13/2024
format: pdf
echo: false
warning: false
---

# Introdcution

## Dataset

We found our dataset from Kaggle and the dataset used for this analysis is the Netflix dataset, which contains metadata about Netflix's movie and TV shows. It provides a comprehensive view of the Netflix's catalog and is widely used for research and analysis in media trends.

<Should be included> 

1. Describe the provenance of the data \* Where did you get the data \* Who collected the data \* For what purpose \* who/what make up the cases

2.  Explain how data meet the FAIR and/or CARE Principles

-   FAIR Principles:
    -   Findability: Other researchers should be able to find the data - i.e. name files descriptively based on the project. EX 'netflix_titles.csv'
    -   Accessibility: Other researchers should be able to access the data, within reason
    -   Interpretability: Data should use standardized formats/terminologies
    -   Reusability: Data should include detailed metadata to allow reuse

3.  Describe what attributes you'll focus your analysis on

-   Figures and Tables should have appropriate captions and appropriately cross-referenced in the body of your report.

## Data Wrangling

```{r}
# Load dataset
file_path <- "netflix_titles.csv"
netflix_data <- read.csv(file_path)
View(netflix_data)
```

```{r}
summary(netflix_data)
```

```{r}
# Necessary libraries for the entire code
library(dplyr)
library(tidyr)
library(ggplot2)
library(tm)
library(wordcloud)
```

### Handling Missing Values

```{r}
# Find Missing Data
netflix_data[netflix_data == ""] <- NA
netflix_data[netflix_data == " "] <- NA

#colSums(is.na(netflix_data))

# Calculate the number of missing values in each column
missing_data <- colSums(is.na(netflix_data))
print(missing_data)
missing_data_df <- data.frame(Column = names(missing_data), MissingCount = missing_data)

ggplot(missing_data_df, aes(x = reorder(Column, -MissingCount), y = MissingCount, fill = MissingCount)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(
    title = "Missing Data Count by Column",
    x = "Columns",
    y = "Count of Missing Values"
  ) +
  scale_fill_gradient(low = "blue", high = "red") +
  theme(legend.position = "none")
```

-   This graph shows that there are a lot of missing values in 'director' column.

```{r}
# Cleaning Missing Data
  # Replace missing values with "Unknown"
netflix_data$director[is.na(netflix_data$director)] <- "Unknown"
netflix_data$cast[is.na(netflix_data$cast)] <- "Unknown"
netflix_data$country[is.na(netflix_data$country)] <- "Unknown"

colSums(is.na(netflix_data))
```

```{r}
# Save the cleaned dataset
write.csv(netflix_data, "cleaned_netflix_data.csv", row.names = FALSE)
cleaned_data <- read.csv("cleaned_netflix_data.csv")
```

## Exploratory Data Analysis

### 1. Movie vs. TV show

```{r}
# Content Trends
# 1. Bar graph
ggplot(cleaned_data, aes(x = type, fill = type)) +
  geom_bar() +
  scale_fill_manual(values = c("#e50914", "#b20710")) +
  labs(title = "Distribution of Content Types", x = "Type", y = "Count") +
  theme_minimal()

# 2. Pie Chart
# Calculate percentages
content_type_dist <- cleaned_data %>%
  count(type) %>%
  mutate(percentage = n / sum(n) * 100)
# Visualization
ggplot(content_type_dist, aes(x = "", y = n, fill = type)) +
  geom_bar(width = 1, stat = "identity") +  # Bar chart as base
  coord_polar(theta = "y") +                # Convert to pie chart
  scale_fill_manual(values = c("#e50914", "#b20710")) +
  geom_text(aes(label = paste0(round(percentage, 1), "%")),  # Add percentage labels
            position = position_stack(vjust = 0.5)) +     # Center labels
  labs(title = "Distribution of Content Types", x = NULL, y = NULL) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),          # Remove x-axis labels
        axis.ticks = element_blank(),
        panel.grid = element_blank())           # Remove grid lines
```

### 2. Duration

```{r}
# Extract numeric values from duration
cleaned_data$duration_numeric <- as.numeric(gsub("[^0-9]", "", cleaned_data$duration))

# Distribution of duration for movies
movie_duration <- cleaned_data %>%
  filter(type == "Movie")

ggplot(movie_duration, aes(x = duration_numeric)) +
  geom_histogram(binwidth = 10, fill = "#e50914", color = "white") +
  labs(title = "Distribution of Movie Durations", x = "Duration (minutes)", y = "Count") +
  theme_minimal()

```

### 3. Yearly Content

```{r}
# Yearly trend
cleaned_data$year_added <- as.numeric(format(as.Date(cleaned_data$date_added, "%B %d, %Y"), "%Y"))

# Year-wise content count
yearly_content <- cleaned_data %>%
  filter(!is.na(year_added)) %>%
  count(year_added)

# Line plot
ggplot(yearly_content, aes(x = year_added, y = n)) +
  geom_line(color = "#e50914", size = 1.2) +
  geom_point(color = "#b20710", size = 3) +
  labs(title = "Yearly Content Addition", x = "Year", y = "Content Count") +
  theme_minimal()

```

### 4. Top 10 Genre

```{r}
# Genre Trends
genre_data <- cleaned_data %>%
  separate_rows(listed_in, sep = ", ") %>%
  count(listed_in, sort = TRUE) %>%
  slice_max(order_by = n, n = 10)

# Plot top genres
ggplot(genre_data, aes(x = reorder(listed_in, n), y = n, fill = listed_in)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#221f1f", "#b20710", "#e50914", "#f5f5f1",
                               "#8c8c8c", "#d4d4d4", "#660000", "#cc0000",
                               "#990033", "#330000")) +
  coord_flip() +
  labs(title = "Top 10 Genres on Netflix", x = "Genre", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

### 5. Top 10 Country

```{r}
# Top 10 Countries by Content Count

  # Find the top 15 countries 
top_countries <- cleaned_data %>%
  count(country, sort = TRUE) %>%
  top_n(10, n)
  # Visualization
custom_colors <- c("#e50914", "#221f1f", "#f5f5f1", "#8c8c8c",
                   "#660000", "#990033", "#330000",
                   "#ff5733", "#c70039", "#581845")

ggplot(top_countries, aes(x = reorder(country, n), y = n, fill = country)) + 
  geom_bar(stat = "identity") +
  scale_fill_manual(values = custom_colors) +  # Apply custom colors
  coord_flip() +
  labs(title = "Top 10 Countries by Content Count", x = "Country", y = "Count") +
  theme_minimal()+
  theme(legend.position = "none")
```

# Research Questions

## RQ1. What are the most frequently occurring keywords in the 'description' text of Netflix content?

```{r}
# Extract the 'description' column and remove missing values
descriptions <- cleaned_data$description
descriptions <- na.omit(descriptions)

# Combine all descriptions into a single text
text <- paste(descriptions, collapse = " ")

# Create a corpus
corpus <- Corpus(VectorSource(text))

# Preprocess the text: remove punctuation, numbers, stopwords, and convert to lowercase
corpus <- corpus %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords("english"))

# Create a term-document matrix
tdm <- TermDocumentMatrix(corpus)
tdm_matrix <- as.matrix(tdm)

# Sum the frequency of words
word_freq <- sort(rowSums(tdm_matrix), decreasing = TRUE)

# Create a data frame of words and their frequencies
word_data <- data.frame(word = names(word_freq), freq = word_freq)

# Generate the word cloud
set.seed(123) # For consistent result
wordcloud(
  words = word_data$word,
  freq = word_data$freq,
  min.freq = 3, # Set minimum frequency for words to appear
  max.words = 150, # Set the maximum number of words to display
  random.order = FALSE,
  colors = brewer.pal(8, "Dark2")
)

```

### RQ1 Findings

By analyzing frequency of text data efficiently, we used 'word cloud' graph. From research question 1, we found that the word "life" appears prominently, suggesting that many descriptions revolve around stories about human experiences. Similarly, the frequent occurrence of "young", "new", "love" and "family" may indicate Netflix's emphasis on content for family-friendly audiences or younger demographics. \## RQ2.

### RQ2 Findings

## RQ3.

### RQ3 Findings

# Methodology

# Discussion

# References

------------------------------------------------------------------------

# Code Appendix

```{r  codeAppend, ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
